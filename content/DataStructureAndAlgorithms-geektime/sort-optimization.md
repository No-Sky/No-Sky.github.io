---
title: "排序优化：如何实现一个通用的、高性能的排序函数"
author: "nosky"
date: 2019-11-20T9:00:52+08:00
draft: false
tags: ["DataStructure", "Algorithms"]
---

# 排序优化：如何实现一个通用的、高性能的排序函数

## 如何选择合适的排序算法？

如果要实现一个通用的、高效率的排序函数，我们应该选择哪种排序算法？

![img](https://static001.geekbang.org/resource/image/1f/fd/1f6ef7e0a5365d6e9d68f0ccc71755fd.jpg)

线性排序算法的时间复杂度比较低，适用场景比较特殊。所以如果要写一个通用的排序函数，不能选择线性排序算法。

如果对小规模数据进行排序，可以选择时间复杂度是O(n^2)的算法；如果对大规模数据进行排序，时间复杂度是O(nlogn)的算法更加高效。所以**，为了兼顾任意规模数据的排序，一般都会首选时间复杂度是O(nlogn)的排序算法来实现排序函数。**

时间复杂度是O(nlogn)的排序算法不止一个，我们已经讲过的有归并排序、快速排序，后面讲堆的时候我们还会讲到堆排序。堆排序和快速排序都有比较多的应用，比如Java语言采用堆排序实现排序函数，C语言使用快速排序实现排序函数。

不知道你有没有发现，使用归并排序的情况其实并不多。我们知道，快排在最坏情况下的时间复杂度是O(n2)，而归并排序可以做到平均情况、最坏情况下的时间复杂度都是O(nlogn)，从这点上看起来很诱人，那为什么它还是没能得到“宠信”呢？

还记得我们上一节讲的归并排序的空间复杂度吗？归并排序并不是原地排序算法，空间复杂度是O(n)。所以，粗略点、夸张点讲，如果要排序100MB的数据，除了数据本身占用的内存之外，排序算法还要额外再占用100MB的内存空间，空间耗费就翻倍了。

前面我们讲到，快速排序比较适合来实现排序函数，但是，我们也知道，快速排序在最坏情况下的时间复杂度是O(n^2)，如何来解决这个“复杂度恶化”的问题呢？

## 如何优化快速排序？

我们先来看下，为什么最坏情况下快速排序的时间复杂度是O(n\^2)呢？我们前面讲过，如果数据原来就是有序的或者接近有序的，每次分区点都选择最后一个数据，那快速排序算法就会变得非常糟糕，时间复杂度就会退化为O(n\^2)。实际上，**这种O(n^2)时间复杂度出现的主要原因还是因为我们分区点选的不够合理**。

那什么样的分区点是好的分区点呢？或者说如何来选择分区点呢？

最理想的分区点是：**被分区点分开的两个分区中，数据的数量差不多**。

### 1.三数取中法

 我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这3个数的中间值作为分区点。 

### 2.随机法

 随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。 