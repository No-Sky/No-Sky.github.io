---
title: "复杂度分析：如何分析算法的执行效率和资源消耗"
author: "nosky"
date: 2019-11-13T21:00:42+08:00
draft: false
tags: ["DataStructure&Algorithms"]
---
# 复杂度分析：如何分析算法的执行效率和资源消耗

## 大O复杂度表示法

​                                                             $T(n) = O(f(n))$

 其中，T(n)表示代码执行的时间；n表示数据规模的大小；f(n)表示每行代码执行的次数总和。因为这是一个公式，所以用f(n)来表示。公式中的O，表示代码的执行时间T(n)与f(n)表达式成正比。 

 大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。 

## 时间复杂度分析

###  1.只关注循环执行次数最多的一段代码

 **我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了**。这段核心代码执行次数的n的量级，就是整段要分析代码的时间复杂度。 

 ### 2.加法法则：总复杂度等于量级最大的那段代码的复杂度

**总的时间复杂度就等于量级最大的那段代码的时间复杂度**。那我们将这个规律抽象成公式就是：

如果T1(n)=O(f(n))，T2(n)=O(g(n))；那么T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).

### 3.乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

 如果T1(n)=O(f(n))，T2(n)=O(g(n))；那么T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)). 

也就是说，假设T1(n) = O(n)，T2(n) = O(n2)，则T1(n) * T2(n) = O(n3)。落实到具体的代码上，我们可以把乘法法则看成是**嵌套循环**，例子:

```
int cal(int n) {
   int ret = 0; 
   int i = 1;
   for (; i < n; ++i) {
     ret = ret + f(i);
   } 
 } 
 
 int f(int n) {
  int sum = 0;
  int i = 1;
  for (; i < n; ++i) {
    sum = sum + i;
  } 
  return sum;
 }
```

我们单独看cal()函数。假设f()只是一个普通的操作，那第4～6行的时间复杂度就是，T1(n) = O(n)。但f()函数本身不是一个简单的操作，它的时间复杂度是T2(n) = O(n)，所以，整个cal()函数的时间复杂度就是，T(n) = T1(n) * T2(n) = O(n*n) = O(n2)。

## 几种常见时间复杂度实例分析

![](https://static001.geekbang.org/resource/image/37/0a/3723793cc5c810e9d5b06bc95325bf0a.jpg)

 对于刚罗列的复杂度量级，我们可以粗略地分为两类，**多项式量级**和**非多项式量级**。其中，非多项式量级只有两个：O(2n)和O(n!)。 

 ### 1. O(1)

O(1)只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有3行，它的时间复杂度也是O(1），而不是O(3)。

```
 int i = 8;
 int j = 6;
 int sum = i + j;
```

只要代码的执行时间不随n的增大而增长，这样代码的时间复杂度我们都记作O(1)。或者说，**一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)**。

### 2. O(logn)、O(nlogn)

```
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```

根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

![](https://static001.geekbang.org/resource/image/9b/9a/9b1c88264e7a1a20b5954be9bc4bec9a.jpg)

 所以，我们只要知道x值是多少，就知道这行代码执行的次数了。通过2^x=n求解x这个问题我们想高中应该就学过了，我就不多说了。x=log_2(n)，所以，这段代码的时间复杂度就是O(log_2(n)。 

```
 i=1;
 while (i <= n)  {
   i = i * 3;
 }
```

同上述计算方式，这段代码的时间复杂度为O(log3n)。

实际上，不管是以2为底、以3为底，还是以10为底，我们可以把所有对数阶的时间复杂度都记为O(logn)。为什么呢？

我们知道，对数之间是可以互相转换的，log_3(n)就等于log_3(2) * log_2(n)，所以O(log_3(n) = O(C * log_2(n)，其中C=log_3(2)是一个常量。基于我们前面的一个理论：**在采用大O标记复杂度的时候，可以忽略系数，即O(Cf(n)) = O(f(n))**。所以，O(log_2(n)) 就等于O(log_3(n))。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为O(logn)。

### 3.O(m+n)、O(m\*n)

假如代码的复杂度**由两个数据的规模**来决定 ，那么就是怎么的情况呢？

```
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
```

从代码中可以看出，m和n是表示两个数据规模。我们无法事先评估m和n谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是O(m+n)。

 针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。 

## 空间复杂度分析

 时间复杂度的全称是**渐进时间复杂度**，**表示算法的执行时间与数据规模之间的增长关系**。类比一下，空间复杂度全称就是**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**。 

 常见的空间复杂度就是O(1)、O(n)、O(n^2 )，像O(logn)、O(nlogn)这样的对数阶复杂度平时都用不到。 

## 内容总结

 复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n2 )。 